{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vOUfzGZcPjB",
        "outputId": "7b788f20-d43b-4730-fe23-cccf22f2a0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks\")\n"
      ],
      "metadata": {
        "id": "k5x_6O9gcSka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB2pBE3bgOG1",
        "outputId": "9e1dba5c-d25a-421e-8f65-d4966e8be15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "import pandas as pd\n",
        "#import pysindy as ps\n",
        "from tqdm import tqdm\n",
        "from termcolor import colored\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import yaml\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from PolyDiff import PolyDiffPoint\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"font.family\"] = 'Arial'\n",
        "np.set_printoptions(suppress=True)"
      ],
      "metadata": {
        "id": "fuVTmqyOcp30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FitEqu(object):\n",
        "    '''\n",
        "    Sparse regression to fit a equation\n",
        "\n",
        "    1. create dataset\n",
        "    2. preprocess dataset\n",
        "    3. build library\n",
        "    4. fit equation\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(FitEqu, self).__init__()\n",
        "\n",
        "    @staticmethod\n",
        "    def load_dataset(dataset_dir):\n",
        "        '''\n",
        "        load dataset\n",
        "        '''\n",
        "        data=pd.read_csv(dataset_dir)\n",
        "        U = np.array(data['U:0']).reshape(100,63,39)\n",
        "        V = np.array(data['U:1']).reshape(100,63,39)\n",
        "        P = np.array(data['p']).reshape(100,63,39)\n",
        "\n",
        "        A=np.zeros((100*63*39,1))\n",
        "        for i in range(0,len(A)):\n",
        "          A[i]=101325\n",
        "        A=A.reshape(100,63,39)\n",
        "        P = P+A\n",
        "        P = np.transpose(P, axes=[1,2,0])\n",
        "        U = np.transpose(U, axes=[1,2,0])\n",
        "        V = np.transpose(V, axes=[1,2,0])\n",
        "\n",
        "        return U, V, P\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def non_dimensionlize(U, V, P, dx, dy, dt, ref_params, sim_params):\n",
        "        '''\n",
        "        non-dimensionlize dx, dy, and dt\n",
        "        '''\n",
        "        # reference parameters\n",
        "        l_ref, v_ref,p_ref= ref_params['l_ref'], ref_params['v_ref'],ref_params['p_ref']\n",
        "        r_ref=sim_params['rho']\n",
        "        t_ref, w_ref = l_ref / v_ref, v_ref / l_ref\n",
        "\n",
        "        # non-dimensionlize data\n",
        "        U, V, P = U/v_ref, V/v_ref, (P*r_ref)/p_ref\n",
        "        dx, dy, dt = dx / l_ref, dy / l_ref, dt / t_ref\n",
        "\n",
        "        sim_params['mu']=sim_params['niu']*sim_params['rho']\n",
        "        # analyze the dimensionless numbers\n",
        "        Re = v_ref * l_ref * sim_params['rho'] / sim_params['mu']\n",
        "        Fr = ref_params['v_ref'] / float(np.sqrt(sim_params['g'] * ref_params['l_ref']))\n",
        "        Eu = ref_params['p_ref'] / (sim_params['rho'] * ref_params['v_ref']**2)\n",
        "        pi_group = {'Re': Re, 'Fr': Fr, 'Eu': Eu}\n",
        "        print(colored(f'Re: {int(Re)}, coef_best: {round(1 / Re, 6)}', 'red'))\n",
        "        print(colored(f'Eu: {int(Eu)}, coef_best: {round(Eu, 6)}', 'red'))\n",
        "        # print(colored(f'Fr: {int(Fr)}, coef_best: {round(1/Fr/Fr, 6)}', 'red'))\n",
        "        return U, V, P, dx, dy, dt, pi_group\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_points(Nx, Ny, boundary_x, boundary_y, boundary_t):\n",
        "        '''\n",
        "        sample a certain number of points to train\n",
        "        '''\n",
        "        np.random.seed(0)\n",
        "        points, count = {}, 0\n",
        "        num_xy = 300\n",
        "        for _ in range(num_xy):\n",
        "            x = np.random.choice(np.arange(boundary_x, Nx-boundary_x), 1)[0]\n",
        "            y = np.random.choice(np.arange(boundary_y, Ny-boundary_y), 1)[0]\n",
        "            for t in range(10, 100, 10):\n",
        "                points[count] = [x, y, t]\n",
        "                count = count + 1\n",
        "        return points\n",
        "\n",
        "    @staticmethod\n",
        "    def cal_derivatives(U, V, P, points, boundary_x, boundary_y, boundary_t, dx, dy, dt, deg=5):\n",
        "        num_points = len(points)\n",
        "        p = np.zeros((num_points,1))\n",
        "        u = np.zeros((num_points,1))\n",
        "        v = np.zeros((num_points,1))\n",
        "        ut, vt = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
        "        ux, vx = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
        "        uy, vy = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
        "        uxx, vxx = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
        "        uxy, vxy = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
        "        uyy, vyy = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
        "        px, py = np.zeros((num_points,1)), np.zeros((num_points,1))\n",
        "\n",
        "        Nx_sample, Ny_sample, Nt_sample = 2*boundary_x-1, 2*boundary_y-1, 2*boundary_t-1\n",
        "\n",
        "        for idx_p in tqdm(points.keys()):\n",
        "            [x, y, t] = points[idx_p]\n",
        "            u[idx_p] = U[x, y, t]\n",
        "            v[idx_p] = V[x, y, t]\n",
        "            p[idx_p] = P[x, y, t]\n",
        "\n",
        "            ut_part = U[x, y, t-int((Nt_sample-1)/2):t+int((Nt_sample+1)/2)]\n",
        "            ux_part = U[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y, t]\n",
        "            uy_part = U[x, y-int((Ny_sample-1)/2):y+int((Ny_sample+1)/2), t]\n",
        "            ux_part_yp = U[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y+1, t]\n",
        "            ux_part_ym = U[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y-1, t]\n",
        "\n",
        "            vt_part = V[x, y, t-int((Nt_sample-1)/2):t+int((Nt_sample+1)/2)]\n",
        "            vx_part = V[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y, t]\n",
        "            vy_part = V[x, y-int((Ny_sample-1)/2):y+int((Ny_sample+1)/2), t]\n",
        "            vx_part_yp = V[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y+1, t]\n",
        "            vx_part_ym = V[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y-1, t]\n",
        "\n",
        "            px_part = P[x-int((Nx_sample-1)/2):x+int((Nx_sample+1)/2), y, t]\n",
        "            py_part = P[x, y-int((Ny_sample-1)/2):y+int((Ny_sample+1)/2), t]\n",
        "\n",
        "            ut[idx_p] = PolyDiffPoint(ut_part, np.arange(Nt_sample)*dt, deg, 1)[0]\n",
        "            ux_diff = PolyDiffPoint(ux_part, np.arange(Nx_sample)*dx, deg, 2)\n",
        "            uy_diff = PolyDiffPoint(uy_part, np.arange(Ny_sample)*dy, deg, 2)\n",
        "            ux_diff_yp = PolyDiffPoint(ux_part_yp, np.arange(Nx_sample)*dx, deg, 2)\n",
        "            ux_diff_ym = PolyDiffPoint(ux_part_ym, np.arange(Nx_sample)*dx, deg, 2)\n",
        "\n",
        "            vt[idx_p] = PolyDiffPoint(vt_part, np.arange(Nt_sample)*dt, deg, 1)[0]\n",
        "            vx_diff = PolyDiffPoint(vx_part, np.arange(Nx_sample)*dx, deg, 2)\n",
        "            vy_diff = PolyDiffPoint(vy_part, np.arange(Ny_sample)*dy, deg, 2)\n",
        "            vx_diff_yp = PolyDiffPoint(vx_part_yp, np.arange(Nx_sample)*dx, deg, 2)\n",
        "            vx_diff_ym = PolyDiffPoint(vx_part_ym, np.arange(Nx_sample)*dx, deg, 2)\n",
        "\n",
        "            ux[idx_p], uxx[idx_p] = ux_diff[0], ux_diff[1]\n",
        "            uy[idx_p], uyy[idx_p] = uy_diff[0], uy_diff[1]\n",
        "            uxy[idx_p] = (ux_diff_yp[0] - ux_diff_ym[0]) / (2 * dy)\n",
        "\n",
        "            vx[idx_p], vxx[idx_p] = vx_diff[0], vx_diff[1]\n",
        "            vy[idx_p], vyy[idx_p] = vy_diff[0], vy_diff[1]\n",
        "            vxy[idx_p] = (vx_diff_yp[0] - vx_diff_ym[0]) / (2 * dy)\n",
        "\n",
        "            px[idx_p] = PolyDiffPoint(px_part, np.arange(Nx_sample)*dx, deg, 1)[0]\n",
        "            py[idx_p] = PolyDiffPoint(py_part, np.arange(Ny_sample)*dy, deg, 1)[0]\n",
        "\n",
        "        base_library = [u, v, p, ut, ux, uy, uxx, uxy, uyy, vt, vx, vy, vxx, vxy, vyy, px, py]\n",
        "        return base_library\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_library(base_library, sim_params, ref_params):\n",
        "        '''\n",
        "        calculate derivatives and build library for sparse regression\n",
        "        '''\n",
        "        u, v, p, ut, ux, uy, uxx, uxy, uyy, vt, vx, vy, vxx, vxy, vyy, px, py = base_library\n",
        "        g_x = np.zeros_like(u)\n",
        "        g_y = np.ones_like(u) * sim_params['g'] * ref_params['l_ref'] / ref_params['v_ref']**2\n",
        "        # ########################standard sindy library#########################\n",
        "        # X_library = [u*ux, v*uy, uxx, uyy, px]\n",
        "        # names = ['u*ux', 'v*uy', 'uxx', 'uyy', 'px']\n",
        "\n",
        "        # #########################rotationial invariance#########################\n",
        "        ########################## More terms (6 terms in total, 4 independent terms)##########################\n",
        "        ut_ = np.concatenate([ut+vt, vt+ut])\n",
        "        u_ = np.concatenate([u+v, v+u])\n",
        "        uu_ = np.concatenate([u*(u+v), v*(v+u)])\n",
        "        vu_ = np.concatenate([v*(u+v), u*(v+u)])\n",
        "\n",
        "        ux_ = np.concatenate([ux+vx, vy+uy])\n",
        "        uy_ = np.concatenate([uy+vy, vx+ux])\n",
        "        uxx_ = np.concatenate([uxx+vxx, vyy+uyy])\n",
        "        uyy_ = np.concatenate([uyy+vyy, vxx+uxx])\n",
        "\n",
        "        uux_ = np.concatenate([u*(ux+vx), v*(vy+uy)])\n",
        "        uuy_ = np.concatenate([u*(uy+vy), v*(vx+ux)])\n",
        "        uuxx_ = np.concatenate([u*(uxx+vxx), v*(vyy+vyy)])\n",
        "        uuyy_ = np.concatenate([u*(uyy+vyy), v*(vxx+uxx)])\n",
        "\n",
        "        vux_ = np.concatenate([v*(ux+vx), u*(vy+uy)])\n",
        "        vuy_ = np.concatenate([v*(uy+vy), u*(vx+ux)])\n",
        "        vuxx_ = np.concatenate([v*(uxx+vxx), u*(vyy+vyy)])\n",
        "        vuyy_ = np.concatenate([v*(uyy+vyy), u*(vxx+uxx)])\n",
        "\n",
        "        uuxx_ = np.concatenate([u*(uxx+vxx), v*(vyy+vyy)])\n",
        "        uuyy_ = np.concatenate([u*(uyy+vyy), v*(vxx+uxx)])\n",
        "        vuxx_ = np.concatenate([v*(uxx+vxx), u*(vyy+vyy)])\n",
        "        vuyy_ = np.concatenate([v*(uyy+vyy), u*(vxx+uxx)])\n",
        "\n",
        "        p_ = np.concatenate([p, p])\n",
        "        px_ = np.concatenate([px+py, py+px])\n",
        "\n",
        "        ut, u, uu, vu, ux, uy, uxx, uyy = ut_, u_, uu_, vu_, ux_, uy_, uxx_, uyy_\n",
        "        uux, uuy, uuxx, uuyy, vux, vuy, vuxx, vuyy, px = uux_, uuy_, uuxx_, uuyy_, vux_, vuy_, vuxx_, vuyy_, px_\n",
        "        p = p_\n",
        "        mu = np.ones_like(u)*sim_params['niu']*sim_params['rho']\n",
        "        diameter=np.ones_like(u)*ref_params['l_ref']\n",
        "        v_init=np.ones_like(u)*ref_params['v_ref']\n",
        "        density=np.ones_like(u)*sim_params['rho']\n",
        "        p_init=np.ones_like(u)*ref_params['p_ref']\n",
        "\n",
        "\n",
        "        # term and position: (uux: 7, vuy: 12, uxx: 5, uyy: 6, px: 16)\n",
        "        X_library = [\n",
        "            u, uu, vu, ux, uy,\n",
        "            uxx, uyy, uux, uuy, uuxx,\n",
        "            uuyy, vux, vuy, vuxx, vuyy,\n",
        "            p, px]\n",
        "        names = ['u', 'uu', 'vu', 'ux', 'uy', 'uxx', 'uyy', 'uux',\n",
        "                'uuy', 'uuxx', 'uuyy', 'vux', 'vuy', 'vuxx', 'vuyy', 'p', 'px', 'mu', 'diameter', 'v_init', 'density', 'p_init']\n",
        "        xx=[ mu, diameter, v_init, density, p_init]\n",
        "\n",
        "        # X_library = [uux, vuy, uxx, uyy, px]\n",
        "        # names = ['uux', 'vuy', 'uxx', 'uyy', 'px']\n",
        "        ##########################Reshape data##########################\n",
        "        X_library = np.squeeze(np.stack(X_library, axis=-1))\n",
        "        xx = np.squeeze(np.stack(xx, axis=-1))\n",
        "        y_library = ut.reshape(-1, 1)\n",
        "\n",
        "        return X_library, y_library, names, xx\n",
        "\n",
        "    @staticmethod\n",
        "    def normalization(X_library, y_library):\n",
        "        '''\n",
        "        Rescale the data by each column\n",
        "        rescale the data by the absolute mean for each column\n",
        "        '''\n",
        "        norm_coef = np.mean(np.abs(np.mean(X_library, axis=0)))\n",
        "        X_library = X_library / norm_coef\n",
        "        y_library = y_library / norm_coef\n",
        "        return X_library, y_library, norm_coef\n",
        "\n",
        "    @staticmethod\n",
        "    def check_library(X_library, y_library):\n",
        "        '''\n",
        "        check whether the library has any Nan\n",
        "        '''\n",
        "        if np.any(np.isnan(X_library)) or np.any(np.isnan(y_library)):\n",
        "            print('Nan exists in library.')\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    @staticmethod\n",
        "    def check_equ(X_library, y_library, pi_group):\n",
        "        '''\n",
        "        check the r2 for the target equation\n",
        "        '''\n",
        "        pred_best = - X_library[:, 7] - X_library[:, 12]\\\n",
        "                    + 1/pi_group['Re'] * (X_library[:, 5] + X_library[:, 6]) \\\n",
        "                    - X_library[:, 16] * pi_group['Eu']\n",
        "        pred_best = pred_best.reshape(-1,1)\n",
        "        r2 = r2_score(y_library, pred_best)\n",
        "        print(f\"Analytical r2_score: {round(r2, 6)}\")\n",
        "\n",
        "        pred_best = - X_library[:, 7] - X_library[:, 12]\\\n",
        "                    - X_library[:, 16] * pi_group['Eu']\n",
        "        pred_best = pred_best.reshape(-1,1)\n",
        "        r2_2 = r2_score(y_library, pred_best)\n",
        "        print(f\"Analytical r2_score (no 1/Re): {round(r2_2, 6)}\")\n",
        "        print('difference', r2-r2_2)\n",
        "        return None"
      ],
      "metadata": {
        "id": "CmByrEg9hRR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = '/content/drive/MyDrive/Colab Notebooks/config_Euler_2cylinder_clean.yml.'\n",
        "\n",
        "config = yaml.load(open(config_path, 'r'), Loader=yaml.FullLoader)\n",
        "case_id_list = list(config['case_id_list'].keys())\n",
        "\n",
        "\n",
        "\n",
        "def prepare_dataset(is_show=False):\n",
        "    '''\n",
        "    prepare a sets of dataset\n",
        "    '''\n",
        "    res = []\n",
        "    fit_equ = FitEqu()\n",
        "    c=[]\n",
        "    d=[]\n",
        "    e=[]\n",
        "    c=pd.DataFrame(c)\n",
        "    d=pd.DataFrame(d)\n",
        "    e=pd.DataFrame(e)\n",
        "\n",
        "\n",
        "    for case_id in case_id_list:\n",
        "\n",
        "        print('*' * 40, case_id)\n",
        "        case_info = config['case_id_list'][case_id]\n",
        "        Nx, Ny = 200, 100\n",
        "        dx, dy = 6/Nx, 3/Ny\n",
        "\n",
        "        ref_params = case_info['ref_params']\n",
        "        sim_params = case_info['sim_params']\n",
        "\n",
        "        sim_params['mu']=sim_params['niu']*sim_params['rho']\n",
        "        dt = sim_params['dt']\n",
        "\n",
        "        # parameters for sparse regression\n",
        "        #x_range, y_range = case_info['x_range'], case_info['y_range']\n",
        "        boundary_x, boundary_y, boundary_t = case_info['fitting']['boundary_num']  # default is 5\n",
        "        deg = case_info['fitting']['deg']               # polynomial degree default is 3\n",
        "\n",
        "        #####################Prepare Dataset#####################\n",
        "        # generate data and save to a folder\n",
        "        U, V, W = fit_equ.load_dataset(case_info['dataset_dir'])\n",
        "        #U, V, W = fit_equ.select_sub_domain(U, V, W, x_range, y_range)\n",
        "        # non-dimensionlize data and dx, dy, dt\n",
        "        U, V, W, dx, dy, dt, pi_group = fit_equ.non_dimensionlize(U, V, W, dx, dy, dt, ref_params, sim_params)\n",
        "        Nx, Ny, Nt = W.shape\n",
        "        # sample points\n",
        "        points = fit_equ.sample_points(Nx, Ny, boundary_x, boundary_y, boundary_t)\n",
        "        # plot the 1st frame\n",
        "        # if is_show: fig = plt.figure(figsize=(6, 4)); plt.imshow(V[:, :, 0].T)\n",
        "\n",
        "        #####################Prepare library#####################\n",
        "        base_library = fit_equ.cal_derivatives(\n",
        "            U, V, W, points, boundary_x, boundary_y, boundary_t, dx, dy, dt, deg)\n",
        "\n",
        "        X_library, y_library, names, xx = fit_equ.parse_library(base_library, sim_params, ref_params)\n",
        "        X_library, y_library, norm_coef = fit_equ.normalization(X_library, y_library)\n",
        "\n",
        "        X_library=pd.DataFrame(X_library)\n",
        "        c=pd.concat([c,X_library],ignore_index=True)\n",
        "        xx=pd.DataFrame(xx)\n",
        "        e=pd.concat([e,xx],ignore_index=True)\n",
        "        y_library=pd.DataFrame(y_library)\n",
        "        d=pd.concat([d,y_library],ignore_index=True)\n",
        "\n",
        "    X_library=c.values\n",
        "    y_library=d.values\n",
        "    xx=e.values\n",
        "    return X_library, y_library, xx\n",
        "X_library, y_library, xx = prepare_dataset(True)\n",
        "\n"
      ],
      "metadata": {
        "id": "qlvg48dGwPzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74ce21d-59f2-4524-e8a6-21827582d296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************** v2-Re-2000\n",
            "Re: 2000, coef_best: 0.0005\n",
            "Eu: 16000, coef_best: 16000.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2700/2700 [00:19<00:00, 139.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************** v1-Re-2600\n",
            "Re: 2600, coef_best: 0.000385\n",
            "Eu: 10355, coef_best: 10355.029586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2700/2700 [00:16<00:00, 165.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************** v3-Re-3000\n",
            "Re: 3000, coef_best: 0.000333\n",
            "Eu: 5341, coef_best: 5341.880342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2700/2700 [00:22<00:00, 120.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_library.shape,y_library.shape,xx.shape)\n",
        "X1_library=X_library[0:5400]\n",
        "X2_library=X_library[5400:10800]\n",
        "X3_library=X_library[10800:16200]\n",
        "y1_library=y_library[0:5400]\n",
        "y2_library=y_library[5400:10800]\n",
        "y3_library=y_library[10800:16200]\n",
        "X1=np.concatenate((X1_library,y1_library),axis=1)\n",
        "X2=np.concatenate((X2_library,y2_library),axis=1)\n",
        "X3=np.concatenate((X3_library,y3_library),axis=1)\n",
        "X1=pd.DataFrame(X1)\n",
        "X2=pd.DataFrame(X2)\n",
        "X3=pd.DataFrame(X3)\n",
        "X1.to_csv('/content/drive/MyDrive/Colab Notebooks/EulerX1.csv')\n",
        "X2.to_csv('/content/drive/MyDrive/Colab Notebooks/EulerX2.csv')\n",
        "X3.to_csv('/content/drive/MyDrive/Colab Notebooks/EulerX3.csv')\n",
        "\n",
        "aaa=pd.DataFrame(X_library)\n",
        "aaa.to_csv('/content/drive/MyDrive/Colab Notebooks/Euler自变量.csv')\n",
        "bbb=pd.DataFrame(y_library)\n",
        "bbb.to_csv('/content/drive/MyDrive/Colab Notebooks/Euler因变量.csv')\n",
        "ccc=pd.DataFrame(xx)\n",
        "ccc.to_csv('/content/drive/MyDrive/Colab Notebooks/Euler量纲数.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds5vFrQL3x0M",
        "outputId": "12094576-bcfc-4487-e473-d3f4d634e765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16200, 17) (16200, 1) (16200, 5)\n"
          ]
        }
      ]
    }
  ]
}